{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 7.442768096923828\n",
      "Epoch 2, Loss: 2.674093008041382\n",
      "Epoch 3, Loss: 0.010730520822107792\n",
      "Epoch 4, Loss: 0.0024688427802175283\n",
      "Epoch 5, Loss: 0.0031436732970178127\n",
      "Epoch 6, Loss: 0.003716964041814208\n",
      "Epoch 7, Loss: 0.00424676900729537\n",
      "Epoch 8, Loss: 0.003011136082932353\n",
      "Epoch 9, Loss: 0.004186884965747595\n",
      "Epoch 10, Loss: 0.002674547955393791\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "\n",
    "# 加载BERT模型和分词器\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 准备训练数据\n",
    "sentence_a = \"The quick brown fox jumps over the lazy dog.\"\n",
    "sentence_b = \"The dog was not amused.\"\n",
    "sentence_c = \"A completely random sentence.\"\n",
    "\n",
    "# 正样本（标签为1）\n",
    "positive_input = tokenizer(sentence_a, sentence_b, return_tensors='pt', padding='max_length', max_length=64, truncation=True)\n",
    "positive_labels = torch.tensor([1])\n",
    "\n",
    "# 负样本（标签为0）\n",
    "negative_input = tokenizer(sentence_a, sentence_c, return_tensors='pt', padding='max_length', max_length=64, truncation=True)\n",
    "negative_labels = torch.tensor([0])\n",
    "\n",
    "# 合并输入和标签\n",
    "inputs = {key: torch.cat([positive_input[key], negative_input[key]]) for key in positive_input}\n",
    "labels = torch.cat([positive_labels, negative_labels])\n",
    "\n",
    "# 训练模型\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(**inputs, next_sentence_label=labels)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
